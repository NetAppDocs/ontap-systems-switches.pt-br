---
permalink: switch-netapp-cn1610/migrate-fas22xx-systems.html 
sidebar: sidebar 
keywords: migrate, two-node switched cluster, fas22xx systems, single, network connection 
summary: Se você possui sistemas FAS22xx em um cluster existente de dois nós sem switch, no qual cada módulo controlador tem uma única conexão 10 GbE direta para conectividade do cluster, você pode usar a opção de rede de cluster sem switch e substituir a conectividade direta direta por conexões de switch. 
---
= Migre para um cluster comutado de dois nós em sistemas FAS22xx com uma única conexão de rede de cluster.
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Se você possui sistemas FAS22xx em um cluster existente de dois nós sem switch, no qual cada módulo controlador tem uma única conexão 10 GbE direta para conectividade do cluster, você pode usar a opção de rede de cluster sem switch e substituir a conectividade direta direta por conexões de switch.



== Requisitos de revisão

.Antes de começar
Certifique-se de ter o seguinte:

* Duas conexões de cluster para migrar de uma configuração sem switch para uma configuração com switch.
* O cluster está íntegro e consiste em dois nós conectados em uma configuração back-to-back.
* Os nós estão executando o ONTAP 8.2 ou posterior.
* O recurso de cluster sem switch não pode ser usado com mais de dois nós.
* Todas as portas do cluster estão no `up` estado.


.Informações relacionadas
https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_suppress_automatic_case_creation_during_scheduled_maintenance_windows["Artigo 1010449 da Base de Conhecimento da NetApp : Como suprimir a criação automática de casos durante janelas de manutenção programadas"^]



== Migre os switches

Este procedimento não é disruptivo, remove a conectividade direta do cluster em um ambiente sem switch e substitui cada conexão com o switch por uma conexão com o nó parceiro.



=== Etapa 1: Prepare-se para a migração

. Altere o nível de privilégio para avançado, inserindo `y` Quando solicitado a continuar:
+
`set -privilege advanced`

+
O prompt avançado(`*>` ) aparece.

. Verifique o status do cluster dos nós no console do sistema de qualquer um dos nós:
+
`cluster show`

+
.Mostrar exemplo
[%collapsible]
====
O exemplo a seguir exibe informações sobre a integridade e a elegibilidade dos nós no cluster:

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Verifique o status do par HA no console do sistema de qualquer um dos nós: `storage failover show`
+
.Mostrar exemplo
[%collapsible]
====
O exemplo a seguir mostra o estado do nó 1 e do nó 2:

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Se o AutoSupport estiver ativado neste cluster, suprima a criação automática de casos invocando uma mensagem do AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
`x`é a duração da janela de manutenção em horas.

+

NOTE: A mensagem notifica o suporte técnico sobre esta tarefa de manutenção, de forma que a criação automática de chamados seja suprimida durante o período de manutenção.

+
.Mostrar exemplo
[%collapsible]
====
O comando a seguir suprime a criação automática de casos por duas horas:

[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=2h
----
====
. Verifique se o estado atual do cluster sem switch é `true` Em seguida, desative o modo de cluster sem interruptor:
+
`network options switchless-cluster modify -enabled false`

. Assuma o controle do nó alvo:
+
`storage failover takeover -ofnode _target_node_name_`

+
Não importa qual nó seja o nó alvo.  Quando o controle é assumido, o nó de destino reinicia automaticamente e exibe a `Waiting for giveback...` mensagem.

+
O nó ativo agora está fornecendo dados para o nó parceiro (alvo) que foi assumido.

. Aguarde dois minutos após a tomada de controle do nó afetado para confirmar se a tomada de controle foi concluída com sucesso.
. Com o nó alvo mostrando o `Waiting for giveback...` mensagem, desligue-a.
+
O método que você usa para desligar o nó depende de você usar o gerenciamento remoto por meio do Processador de Serviço (SP) do nó.

+
|===
| Se SP | Então... 


 a| 
Está configurado
 a| 
Faça login no nó SP com problemas e, em seguida, desligue o sistema: `system power off`



 a| 
Não está configurado
 a| 
Ao receber a mensagem de nó comprometido, pressione `Ctrl-C` e então responda `y` para interromper o nó.

|===




=== Etapa 2: Configurar cabos e portas

. Em cada módulo controlador, desconecte o cabo que liga a porta de cluster 10 GbE ao cluster sem switch.
. Conecte a porta de cluster 10 GbE ao switch em ambos os módulos controladores.
. Verifique se as portas de cluster de 10 GbE conectadas ao switch estão configuradas para fazer parte da mesma VLAN.
+
Se você planeja conectar as portas de cluster em cada módulo controlador a switches diferentes, deverá verificar se as portas às quais as portas de cluster estão conectadas em cada switch estão configuradas para a mesma VLAN e se o trunking está configurado corretamente em ambos os switches.

. Devolva o espaço de armazenamento ao nó de destino:
+
`storage failover giveback -ofnode node2`

. Acompanhe o progresso da operação de devolução:
+
`storage failover show-giveback`

. Após a conclusão da operação de devolução, confirme se o par HA está saudável e se a aquisição é possível:
+
`storage failover show`

+
.Mostrar exemplo
[%collapsible]
====
O resultado deverá ser semelhante ao seguinte:

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Verifique se as LIFs da porta do cluster estão funcionando corretamente:
+
`network interface show -role cluster`

+
.Mostrar exemplo
[%collapsible]
====
O exemplo a seguir mostra que os LIFs são `up` nos nós 1 e 2 e que os resultados da coluna "É Casa" são `true` :

[listing]
----

cluster::*> network interface show -role cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
node1
            clus1        up/up    192.168.177.121/24  node1        e1a     true
node2
            clus1        up/up    192.168.177.123/24  node2        e1a     true

2 entries were displayed.
----
====
. Verifique o status do cluster dos nós no console do sistema de qualquer um dos nós:
+
`cluster show`

+
.Mostrar exemplo
[%collapsible]
====
O exemplo a seguir exibe informações sobre a integridade e a elegibilidade dos nós no cluster:

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Verifique a conectividade das interfaces do cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e posterior
--
Você pode usar o `network interface check cluster-connectivity` Comando para iniciar uma verificação de acessibilidade para conectividade do cluster e, em seguida, exibir os detalhes:

`network interface check cluster-connectivity start`e `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Aguarde alguns segundos antes de executar o `show` comando para exibir os detalhes.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Todas as versões do ONTAP
--
Para todas as versões do ONTAP , você também pode usar o `cluster ping-cluster -node <name>` comando para verificar a conectividade:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Etapa 3: Conclua o procedimento

. Se você desativou a criação automática de casos, reative-a enviando uma mensagem do AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
.Mostrar exemplo
[%collapsible]
====
[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=END
----
====
. Altere o nível de privilégio de volta para administrador:
+
`set -privilege admin`


