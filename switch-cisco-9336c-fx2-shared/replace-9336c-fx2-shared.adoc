---
sidebar: sidebar 
permalink: switch-cisco-9336c-fx2-shared/replace-9336c-fx2-shared.html 
keywords:  
summary:  
---
= Substitua um switch compartilhado Cisco Nexus 9336C-FX2
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Você pode substituir um switch compartilhado Nexus 9336C-FX2 com defeito. Este é um procedimento sem interrupções (NDU).

.Antes de começar
Antes de efetuar a substituição do interrutor, certifique-se de que:

* No cluster existente e infra-estrutura de rede:
+
** O cluster existente é verificado como completamente funcional, com pelo menos um switch de cluster totalmente conetado.
** Todas as portas de cluster são *up*.
** Todas as interfaces lógicas de cluster (LIFs) são *up* e em suas portas domésticas.
** O comando ping-cluster -nó node1 do cluster do ONTAP deve indicar que a conetividade básica e a comunicação maior do que a PMTU são bem-sucedidas em todos os caminhos.


* Para o interrutor de substituição Nexus 9336C-FX2:
+
** A conetividade de rede de gerenciamento no switch de substituição está funcional.
** O acesso do console ao interrutor de substituição está no lugar.
** As conexões de nó são as portas 1/1 a 1/34:
** Todas as portas ISL (Inter-Switch Link) estão desativadas nas portas 1/35 e 1/36.
** O arquivo de configuração de referência desejado (RCF) e o interrutor de imagem do sistema operacional NX-os são carregados no switch.
** Quaisquer personalizações de sites anteriores, como STP, SNMP e SSH, devem ser copiadas para o novo switch.




.Sobre os exemplos
Você deve executar o comando para migração de um cluster LIF do nó onde o cluster LIF está hospedado.

Os exemplos deste procedimento utilizam a seguinte nomenclatura de switch e nó:

* Os nomes dos switches Nexus 9336C-FX2 existentes são _SH1_ e _SH2_.
* O nome dos novos switches Nexus 9336C-FX2 são _newsh1_ e _newsh2_.
* Os nomes dos nós são _node1_ e _node2_.
* As portas de cluster em cada nó são chamadas _E3A_ e _e3b_.
* Os nomes de LIF do cluster são `node1_clus1` e `node1_clus2` para node1 `node2_clus1` e e `node2_clus2` node2.
* O prompt para alterações em todos os nós de cluster é cluster1::*>.
+

NOTE: O seguinte procedimento baseia-se na seguinte topologia de rede:



.Mostrar exemplo de topologia
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false
4 entries were displayed.


cluster1::*> *network interface show -vserver Cluster*
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
4 entries were displayed.

cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e3a    sh1                       Eth1/2            N9K-C9336C
            e3b    sh2                       Eth1/2            N9K-C9336C

node1      /cdp
            e3a    sh1                       Eth1/1            N9K-C9336C
            e3b    sh2                       Eth1/1            N9K-C9336C
4 entries were displayed.

sh1# *show cdp neighbors*
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute
Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         144    H           FAS2980       e3a
node2              Eth1/2         145    H           FAS2980       e3a
sh2                Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
sh2 (FDO220329V5)   Eth1/36       176    R S I s     N9K-C9336C    Eth1/36
Total entries displayed: 4

sh2# *show cdp neighbors*
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute
Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       eb
node2              Eth1/2         124    H           FAS2980       eb
sh1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
sh1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36
Total entries displayed: 4
----
====
.Passos
. Se o AutoSupport estiver ativado neste cluster, suprimir a criação automática de casos invocando uma mensagem AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
Onde x é a duração da janela de manutenção em horas.

. Opcional: Instale o RCF e a imagem apropriados no interrutor, newsh2, e faça os preparativos necessários para o local.
+
.. Se necessário, verifique, baixe e instale as versões apropriadas do software RCF e NX-os para o novo switch. Se você tiver verificado que o novo switch está corretamente configurado e não precisa de atualizações para o software RCF e NX-os, continue para <<step3,Passo 3>>.
.. Vá para a página Descrição do arquivo de configuração de referência do cluster e gerenciamento de switches de rede do NetApp no site de suporte da NetApp.
.. Clique no link da Matriz de Compatibilidade de rede de Cluster e rede de Gerenciamento e anote a versão necessária do software do switch.
.. Clique na seta para trás do navegador para retornar à página Descrição, clique EM CONTINUAR, aceite o contrato de licença e vá para a página Download.
.. Siga as etapas na página Download para baixar os arquivos RCF e NX-os corretos para a versão do software ONTAP que você está instalando.


. [[step3]]no novo switch, faça login como admin e encerre todas as portas que serão conetadas às interfaces do cluster de nós (portas 1/1 a 1/34). Se o interrutor que você está substituindo não estiver funcional e estiver desligado, vá para <<step4,Passo 4>>. As LIFs nos nós de cluster já devem ter falhado para a outra porta de cluster para cada nó.
+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
newsh2# *config*
Enter configuration commands, one per line. End with CNTL/Z.
newsh2(config)# *interface e1/1-34*
newsh2(config-if-range)# *shutdown*
----
====


. [[step4]]Verifique se todas as LIFs do cluster têm a reversão automática ativada.
+
`network interface show - vserver Cluster -fields auto-revert`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::> *network interface show -vserver Cluster -fields auto-revert*
             Logical
Vserver      Interface     Auto-revert
------------ ------------- -------------
Cluster      node1_clus1   true
Cluster      node1_clus2   true
Cluster      node2_clus1   true
Cluster      node2_clus2   true
4 entries were displayed.
----
====


. [[step5]] Verifique a conetividade das interfaces de cluster remotas:


[role="tabbed-block"]
====
.ONTAP 9.9,1 e posterior
--
Você pode usar o `network interface check cluster-connectivity` comando para iniciar uma verificação de acessibilidade para conetividade de cluster e, em seguida, exibir os detalhes:

`network interface check cluster-connectivity start` e `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* espere alguns segundos antes de executar o `show` comando para exibir os detalhes.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Todos os lançamentos do ONTAP
--
Para todas as versões do ONTAP, você também pode usar o `cluster ping-cluster -node <name>` comando para verificar a conetividade:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e3a
Cluster node1_clus2 169.254.49.125 node1 e3b
Cluster node2_clus1 169.254.47.194 node2 e3a
Cluster node2_clus2 169.254.19.183 node2 e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step6]]desligue as portas ISL 1/35 e 1/36 no switch Nexus 9336C-FX2 SH1.
+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
sh1# *configure*
Enter configuration commands, one per line. End with CNTL/Z.
sh1(config)# *interface e1/35-36*
sh1(config-if-range)# *shutdown*
----
====


. [[step7]]Remova todos os cabos do switch Nexus 9336C-FX2 SH2 e, em seguida, conete-os às mesmas portas no switch Nexus C9336C-FX2 newsh2.
. Abra as portas ISLs 1/35 e 1/36 entre os switches SH1 e newsh2 e verifique o status da operação do canal da porta.
+
O Canal de porta deve indicar PO1(SU) e os portos Membros devem indicar eth1/35(P) e eth1/36(P).

+
.Mostrar exemplo
[%collapsible]
====
Este exemplo ativa as portas ISL 1/35 e 1/36 e exibe o resumo do canal da porta no switch SH1.

[listing, subs="+quotes"]
----
sh1# *configure*
Enter configuration commands, one per line. End with CNTL/Z.
sh1 (config)# *int e1/35-36*
sh1 (config-if-range)# *no shutdown*
sh1 (config-if-range)# *show port-channel summary*
Flags:  D - Down        P - Up in port-channel (members)
        I - Individual  H - Hot-standby (LACP only)
        s - Suspended   r - Module-removed
        b - BFD Session Wait
        S - Switched    R - Routed
        U - Up (port-channel)
        p - Up in delay-lacp mode (member)
        M - Not in use. Min-links not met
--------------------------------------------------------------------------------
Group Port-       Type     Protocol  Member       Ports
      Channel
--------------------------------------------------------------------------------
1     Po1(SU)     Eth      LACP      Eth1/35(P)   Eth1/36(P)

sh1 (config-if-range)#
----
====


. [[step9]]Verifique se a porta e3b está ativa em todos os nós:
+
`network port show ipspace Cluster`

+
.Mostrar exemplo
[%collapsible]
====
A saída deve ser como o seguinte:

[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ---------- - - -------- ----
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ----------- -  -------- ----
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/auto    -        false
4 entries were displayed.
----
====


. [[step10]]no mesmo nó que você usou na etapa anterior, reverta o LIF de cluster associado à porta na etapa anterior usando o comando de reversão de interface de rede.
+
Neste exemplo, LIF node1_clus2 no node1 é revertido com sucesso se o valor Casa for verdadeiro e a porta for e3b.

+
Os comandos a seguir retornam LIF node1_clus2 em node1 para a porta inicial E3A e exibe informações sobre os LIFs em ambos os nós. Abrir o primeiro nó é bem-sucedido se a coluna is Home for *true* para ambas as interfaces de cluster e eles mostrarem as atribuições de porta corretas, neste exemplo E3A e e3b em node1.

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current    Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node       Port    Home
----------- ------------ ---------- ------------------ ---------- ------- -----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1      e3a     true
            node1_clus2  up/up      169.254.49.125/16  node1      e3b     true
            node2_clus1  up/up      169.254.47.194/16  node2      e3a     true
            node2_clus2  up/up      169.254.19.183/16  node2      e3a     false
4 entries were displayed.
----
====


. [[step11]]Exibir informações sobre os nós em um cluster:
+
`cluster show`

+
.Mostrar exemplo
[%collapsible]
====
Este exemplo mostra que a integridade do nó para node1 e node2 neste cluster é verdadeira:

[listing, subs="+quotes"]
----
cluster1::*> *cluster show*
Node          Health  Eligibility
------------- ------- ------------
node1         false   true
node2         true    true
----
====


. [[step12]]Verifique se todas as portas de cluster físico estão ativas:
+
`network port show ipspace Cluster`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                                Ignore
                                                    Speed(Mbps)  Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper   Status   Status
--------- ----------- ----------------- ----- ----- ------------ -------- ------
e3a       Cluster     Cluster           up    9000  auto/100000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/100000  healthy  false

Node: node2
                                                                          Ignore
                                                    Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ----- ----- ------------ -------- ------
e3a       Cluster      Cluster          up    9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/100000  healthy  false
4 entries were displayed.
----
====


. [[step13]] Verifique a conetividade das interfaces de cluster remotas:


[role="tabbed-block"]
====
.ONTAP 9.9,1 e posterior
--
Você pode usar o `network interface check cluster-connectivity` comando para iniciar uma verificação de acessibilidade para conetividade de cluster e, em seguida, exibir os detalhes:

`network interface check cluster-connectivity start` e `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* espere alguns segundos antes de executar o `show` comando para exibir os detalhes.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Todos os lançamentos do ONTAP
--
Para todas as versões do ONTAP, você também pode usar o `cluster ping-cluster -node <name>` comando para verificar a conetividade:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e3a
Cluster node1_clus2 169.254.49.125 node1 e3b
Cluster node2_clus1 169.254.47.194 node2 e3a
Cluster node2_clus2 169.254.19.183 node2 e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step14]]Confirme a seguinte configuração de rede de cluster:
+
`network port show`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                       Speed(Mbps)             Health   Health
Port      IPspace     Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ----------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster     Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster     Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                        Ignore
                                        Speed(Mbps)            Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000 auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000 auto/100000  healthy  false
4 entries were displayed.

cluster1::*> *network interface show -vserver Cluster*
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
4 entries were displayed.

cluster1::> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node2      /cdp
            e3a    sh1    0/2               N9K-C9336C
            e3b    newsh2                    0/2               N9K-C9336C
node1      /cdp
            e3a    sh1                       0/1               N9K-C9336C
            e3b    newsh2                    0/1               N9K-C9336C
4 entries were displayed.

sh1# *show cdp neighbors*
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute
Device-ID            Local Intrfce  Hldtme Capability  Platform      Port ID
node1                Eth1/1         144    H           FAS2980       e3a
node2                Eth1/2         145    H           FAS2980       e3a
newsh2               Eth1/35        176    R S I s     N9K-C9336C    Eth1/35
newsh2               Eth1/36        176    R S I s     N9K-C9336C    Eth1/36
Total entries displayed: 4

sh2# *show cdp neighbors*
Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute
Device-ID          Local Intrfce  Hldtme Capability  Platform      Port ID
node1              Eth1/1         139    H           FAS2980       e3b
node2              Eth1/2         124    H           FAS2980       eb
sh1                Eth1/35        178    R S I s     N9K-C9336C    Eth1/35
sh1                Eth1/36        178    R S I s     N9K-C9336C    Eth1/36
Total entries displayed: 4
----
====


. [[step15]]mova as portas de armazenamento do antigo switch SH2 para o novo switch newsh2.
. Verifique se o storage anexado ao par de HA 1, o switch compartilhado newsh2 está funcionando.
. Verifique se o storage anexado ao par HA 2, o switch compartilhado newsh2 está funcionando:
+
`storage port show -port-type ENET`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
storage::*> *storage port show -port-type ENET*
                                   Speed                            VLAN
Node    Port    Type    Mode       (Gb/s)      State     Status       ID
------- ------- ------- ---------- ----------- --------- --------- -----
node1
        e3a     ENET    storage          100   enabled   online       30
        e3b     ENET    storage            0   enabled   offline      30
        e7a     ENET    storage            0   enabled   offline      30
        e7b     ENET    storage          100   enabled   online       30

node2
        e3a     ENET    storage          100   enabled   online       30
        e3b     ENET    storage            0   enabled   offline      30
        e7a     ENET    storage            0   enabled   offline      30
        e7b     ENET    storage          100   enabled   online       30
----
====


. [[step18]]Verifique se as prateleiras estão cabeadas corretamente:
+
`storage shelf port show -fields remote- device,remote-port`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *storage shelf port show -fields remote-device,remote-port*
shelf id remote-port  remote-device
----- -- ------------ ----------------------------
3.20  0  Ethernet1/13 sh1
3.20  1  Ethernet1/13 newsh2
3.20  2  Ethernet1/14 sh1
3.20  3  Ethernet1/14 newsh2
3.30  0  Ethernet1/15 sh1
3.30  1  Ethernet1/15 newsh2
3.30  2  Ethernet1/16 sh1
3.30  3  Ethernet1/16 newsh2
8 entries were displayed.
----
====


. [[step19]]Remova o interrutor antigo SH2.
. Repita estes passos para o interrutor SH1 e para o novo interrutor newsh1.
. Se você suprimiu a criação automática de casos, reative-a invocando uma mensagem AutoSupport:
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.O que se segue?
link:../switch-cshm/config-overview.html["Configurar o monitoramento de integridade do switch"].
