---
permalink: switch-nvidia-sn2100-storage/migrate-cisco-sn2100-cluster-switch-storage.html 
sidebar: sidebar 
keywords: migrating to a cluster with NVIDIA SN2100 cluster switches, how to migrate 
summary: Você pode migrar switches de cluster Cisco mais antigos sem interrupções para um cluster ONTAP para switches de rede de cluster NVIDIA SN2100. 
---
= Migre de um switch de cluster Cisco para um switch de cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Você pode migrar switches de cluster Cisco sem interrupções para um cluster ONTAP para switches de cluster NVIDIA SN2100. Você deve estar ciente de certas informações de configuração, conexões de portas e requisitos de cabeamento ao substituir alguns switches de cluster Cisco mais antigos por switches de cluster NVIDIA SN2100.

Os seguintes switches de cluster Cisco são suportados:

* Nexus 9336C-FX2
* Nexus 92300YC
* Nexus 5596UP
* Nexus 3232C
* Nexus 3132Q-V


.Antes de começar
Você pode migrar os switches de cluster Cisco mais antigos sem interrupções para um cluster ONTAP para os switches de cluster do NVIDIA SN2100.

* O cluster existente deve estar configurado e funcionando corretamente.
* Todas as portas de cluster devem estar no estado operacional para garantir operações ininterruptas.
* Os switches de cluster do NVIDIA SN2100 devem ser configurados e operando sob a versão adequada do Cumulus Linux instalado com o arquivo de configuração de referência (RCF) aplicado.
* A configuração de rede de cluster existente deve ter o seguinte:
+
** Um cluster NetApp redundante e totalmente funcional usando ambos os switches Cisco mais antigos.
** Conetividade de gerenciamento e acesso ao console aos switches Cisco mais antigos e aos novos switches.
** Todas as LIFs de cluster no estado up com os LIfs de cluster estão em suas portas iniciais.
** Portas ISL ativadas e cabeadas entre os switches Cisco mais antigos e entre os novos switches.


* Consulte o https://hwu.netapp.com/["Hardware Universe"^] para obter detalhes completos sobre as portas suportadas e respetivas configurações.
* Você configurou algumas das portas nos switches NVIDIA SN2100 para serem executadas a 40 GbE ou 100 GbE.
* Você planejou, migrou e documentou a conectividade de 40 GbE e 100 GbE de nós para os switches de cluster NVIDIA SN2100.
+

NOTE: Neste procedimento, os switches de cluster Cisco Nexus 3232C são usados, por exemplo, comandos e saídas.



.Sobre esta tarefa
Os exemplos deste procedimento utilizam a seguinte nomenclatura de switch e nó:

* Os switches de cluster Cisco Nexus 3232C existentes são _C1_ e _C2_.
* Os novos switches de cluster do NVIDIA SN2100 são _SW1_ e _SW2_.
* Os nós são _node1_ e _node2_.
* Os LIFs de cluster são _node1_clus1_ e _node1_clus2_ no nó 1 e _node2_clus1_ e _node2_clus2_ no nó 2 respetivamente.
* O `cluster1::*>` prompt indica o nome do cluster.
* As portas de cluster usadas neste procedimento são _E3A_ e _e3b_.
* As portas breakout tomam o formato: swp[port]s[breakout port 0-3]. Por exemplo, quatro portas breakout no swp1 são _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.
* O interrutor C2 é substituído primeiro pelo interrutor SW2 e, em seguida, o interrutor C1 é substituído pelo interrutor SW1.
+
** O cabeamento entre os nós e o C2 é desconetado do C2 e reconetado ao SW2.
** O cabeamento entre os nós e o C1 é desconetado do C1 e reconetado ao SW1.




.Passos
. Se o AutoSupport estiver ativado neste cluster, suprimir a criação automática de casos invocando uma mensagem AutoSupport: `system node autosupport invoke -node * -type all -message MAINT=xh`
+
onde _x_ é a duração da janela de manutenção em horas.

. Altere o nível de privilégio para avançado, inserindo *y* quando solicitado a continuar: `set -privilege advanced`
+
É apresentado o aviso avançado (*>).

. Desativar a reversão automática nos LIFs do cluster: `network interface modify -vserver Cluster -lif * -auto-revert false`
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Determine o status administrativo ou operacional de cada interface de cluster:
+
Cada porta deve ser exibida para `Link` e saudável para `Health Status`.

+
.. Exibir os atributos da porta de rede: `network port show -ipspace Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
.. Exibir informações sobre as interfaces lógicas e seus nós iniciais designados: `network interface show -vserver Cluster`
+
Cada LIF deve exibir up/up para `Status Admin/Oper` e true para `Is Home`.

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current     Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node        Port    Home
----------- -----------  ---------- ------------------ ----------- ------- ----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1       e3a     true
            node1_clus2  up/up      169.254.49.125/16  node1       e3b     true
            node2_clus1  up/up      169.254.47.194/16  node2       e3a     true
            node2_clus2  up/up      169.254.19.183/16  node2       e3b     true

----


. As portas de cluster em cada nó são conetadas aos switches de cluster existentes da seguinte maneira (da perspetiva dos nós) usando o comando: `network device-discovery show -protocol lldp`
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1 (6a:ad:4f:98:3b:3f)    Eth1/1            -
            e3b    c2 (6a:ad:4f:98:4c:a4)    Eth1/1            -
node2      /lldp
            e3a    c1 (6a:ad:4f:98:3b:3f)    Eth1/2            -
            e3b    c2 (6a:ad:4f:98:4c:a4)    Eth1/2            -
----
. As portas e os switches do cluster são conetados da seguinte maneira (da perspetiva dos switches) usando o comando: `show cdp neighbors`
+
[listing, subs="+quotes"]
----
c1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 Eth1/1         124   H           AFF-A400         e3a
node2                 Eth1/2         124   H           AFF-A400         e3a
c2                    Eth1/31        179   S I s       N3K-C3232C       Eth1/31
c2                    Eth1/32        175   S I s       N3K-C3232C       Eth1/32

c2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 Eth1/1        124    H           AFF-A400         e3b
node2                 Eth1/2        124    H           AFF-A400         e3b
c1                    Eth1/31       175    S I s       N3K-C3232C       Eth1/31
c1                    Eth1/32       175    S I s       N3K-C3232C       Eth1/32
----
. Verifique a conectividade das interfaces de cluster remotas:


[role="tabbed-block"]
====
.ONTAP 9.9,1 e posterior
--
Você pode usar o `network interface check cluster-connectivity` comando para iniciar uma verificação de acessibilidade para conetividade de cluster e, em seguida, exibir os detalhes:

`network interface check cluster-connectivity start` e `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* espere alguns segundos antes de executar o `show` comando para exibir os detalhes.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Todos os lançamentos do ONTAP
--
Para todas as versões do ONTAP, você também pode usar o `cluster ping-cluster -node <name>` comando para verificar a conetividade:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e3a
Cluster node1_clus2 169.254.49.125 node1     e3b
Cluster node2_clus1 169.254.47.194 node2     e3a
Cluster node2_clus2 169.254.19.183 node2     e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:
....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[step8]] no switch C2, encerre as portas conetadas às portas do cluster dos nós.
+
[listing, subs="+quotes"]
----
(c2)# *configure*
Enter configuration commands, one per line. End with CNTL/Z.

(c2)(Config)# *interface*
(c2)(config-if-range)# *shutdown _<interface_list>_*
(c2)(config-if-range)# *exit*
(c2)(Config)# *exit*
(c2)#
----
. Mova as portas do cluster de nós do switch antigo C2 para o novo switch SW2, usando o cabeamento apropriado suportado pelo NVIDIA SN2100.
. Exibir os atributos da porta de rede: `network port show -ipspace Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
. As portas do cluster em cada nó agora são conetadas aos switches do cluster da seguinte maneira, da perspetiva dos nós:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   Eth1/1            -
            e3b    sw2 (b8:ce:f6:19:1a:7e)   swp3              -
node2      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   Eth1/2            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4              -
----
. No switch SW2, verifique se todas as portas do cluster de nós estão ativas: `net show interface`
+
[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. No switch C1, encerre as portas conetadas às portas do cluster dos nós.
+
[listing, subs="+quotes"]
----
(c1)# *configure*
Enter configuration commands, one per line. End with CNTL/Z.

(c1)(Config)# *interface*
(c1)(config-if-range)# *shutdown _<interface_list>_*
(c1)(config-if-range)# *exit*
(c1)(Config)# *exit*
(c1)#
----
. Mova as portas do cluster de nós do switch antigo C1 para o novo switch SW1, usando o cabeamento apropriado suportado pelo NVIDIA SN2100.
. Verifique a configuração final do cluster: `network port show -ipspace Cluster`
+
Cada porta deve ser exibida para `Link` e saudável para `Health Status`.

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
. As portas do cluster em cada nó agora são conetadas aos switches do cluster da seguinte maneira, da perspetiva dos nós:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface       Platform
----------- ------ ------------------------- --------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3            -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4            -
----
. Nos switches SW1 e SW2, verifique se todas as portas do cluster de nós estão ativas: `net show interface`
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw2 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw2 (swp16)       Master: cluster_isl(UP)


cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- -----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Verifique se ambos os nós têm uma conexão com cada switch: `net show lldp`
+
O exemplo a seguir mostra os resultados apropriados para ambos os switches:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3a
swp4       100G   Trunk/L2    node2               e3a
swp15      100G   BondMember  sw2                 swp15
swp16      100G   BondMember  sw2                 swp16

cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3b
swp4       100G   Trunk/L2    node2               e3b
swp15      100G   BondMember  sw1                 swp15
swp16      100G   BondMember  sw1                 swp16
----
. Ativar a reversão automática nos LIFs do cluster: `cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`
. Verifique se todas as LIFs de rede do cluster estão de volta em suas portas domésticas: `network interface show`
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true
----
. Ative o recurso de coleta de logs do monitor de integridade do switch Ethernet para coletar arquivos de log relacionados ao switch, usando os dois comandos: `system switch ethernet log setup-password` E. `system switch ethernet log enable-collection`
+
Introduza: `system switch ethernet log setup-password`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
*sw1*
*sw2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>
----
+
Seguido por: `system switch ethernet log enable-collection`

+
[listing, subs="+quotes"]
----
cluster1::*> *system  switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
+

NOTE: Se algum desses comandos retornar um erro, entre em Contato com o suporte do NetApp.

. Inicie o recurso de coleta de logs de switch: `system switch ethernet log collect -device *`
+
Aguarde 10 minutos e, em seguida, verifique se a coleção de logs foi bem-sucedida usando o comando: `system switch ethernet log show`

+
[listing, subs="+quotes"]
----
cluster1::*> system switch ethernet log show
Log Collection Enabled: true

Index  Switch                       Log Timestamp        Status
------ ---------------------------- -------------------  ---------    
1      sw1 (b8:ce:f6:19:1b:42)      4/29/2022 03:05:25   complete   
2      sw2 (b8:ce:f6:19:1b:96)      4/29/2022 03:07:42   complete
----
. Altere o nível de privilégio de volta para admin: `set -privilege admin`
. Se você suprimiu a criação automática de casos, reative-a invocando uma mensagem AutoSupport: `system node autosupport invoke -node * -type all -message MAINT=END`

