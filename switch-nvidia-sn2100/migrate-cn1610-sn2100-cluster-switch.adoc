---
permalink: switch-nvidia-sn2100/migrate-cn1610-sn2100-cluster-switch.html 
sidebar: sidebar 
keywords: migrate cluster NVIDIA SN2100 cluster switches cn1610 
summary: Você pode migrar switches de cluster NetApp CN1610 de um cluster ONTAP para switches de rede de cluster NVIDIA SN2100 sem interrupções. 
---
= Migrar switches de cluster CN1610 para switches de cluster NVIDIA SN2100
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Você pode migrar switches de cluster NetApp CN1610 de um cluster ONTAP para switches de cluster NVIDIA SN2100. Este é um procedimento não disruptivo.



== Requisitos de revisão

Ao substituir switches de cluster NetApp CN1610 por switches de cluster NVIDIA SN2100, é preciso estar ciente de certas informações de configuração, conexões de porta e requisitos de cabeamento. Verlink:configure-overview-sn2100-cluster.html["Visão geral da instalação e configuração dos switches NVIDIA SN2100"] .

.Interruptores suportados
Os seguintes switches de cluster são suportados:

* NetApp CN1610
* NVIDIA SN2100


Para obter detalhes sobre as portas suportadas e suas configurações, consulte o https://hwu.netapp.com/["Hardware Universe"^] .

.Antes de começar
Verifique se você atende aos seguintes requisitos para sua configuração:

* O cluster existente está configurado corretamente e funcionando.
* Todas as portas do cluster estão no estado *ativo* para garantir operações sem interrupções.
* Os switches de cluster NVIDIA SN2100 estão configurados e operando com a versão correta do Cumulus Linux instalada e com o arquivo de configuração de referência (RCF) aplicado.
* A configuração de rede do cluster existente apresenta as seguintes características:
+
** Um cluster NetApp redundante e totalmente funcional usando switches CN1610.
** Conectividade de gerenciamento e acesso ao console tanto para os switches CN1610 quanto para os novos switches.
** Todas as LIFs do cluster estão ativas, com as LIFs do cluster em suas portas de origem.
** As portas ISL foram habilitadas e conectadas por cabos entre os switches CN1610 e entre os novos switches.


* Algumas portas dos switches NVIDIA SN2100 estão configuradas para operar em 40GbE ou 100GbE.
* Você planejou, migrou e documentou a conectividade de 40GbE e 100GbE dos nós para os switches de cluster NVIDIA SN2100.




== Migre os switches

.Sobre os exemplos
Os exemplos neste procedimento utilizam a seguinte nomenclatura de interruptor e nó:

* Os switches de cluster CN1610 existentes são _c1_ e _c2_.
* Os novos switches de cluster NVIDIA SN2100 são _sw1_ e _sw2_.
* Os nós são _node1_ e _node2_.
* Os LIFs do cluster são _node1_clus1_ e _node1_clus2_ no nó 1, e _node2_clus1_ e _node2_clus2_ no nó 2, respectivamente.
* O `cluster1::*>` O prompt indica o nome do cluster.
* As portas de cluster usadas neste procedimento são _e3a_ e _e3b_.
* As portas de breakout têm o seguinte formato: swp[porta]s[porta de breakout 0-3].  Por exemplo, quatro portas breakout em swp1 são _swp1s0_, _swp1s1_, _swp1s2_ e _swp1s3_.


.Sobre esta tarefa
Este procedimento abrange o seguinte cenário:

* O interruptor c2 é substituído primeiro pelo interruptor sw2.
+
** Desative as portas dos nós do cluster.  Todas as portas devem ser desligadas simultaneamente para evitar instabilidade no cluster.
** Em seguida, o cabeamento entre os nós e o c2 é desconectado do c2 e reconectado ao sw2.


* O interruptor c1 é substituído pelo interruptor sw1.
+
** Desative as portas dos nós do cluster.  Todas as portas devem ser desligadas simultaneamente para evitar instabilidade no cluster.
** Em seguida, o cabeamento entre os nós e c1 é desconectado de c1 e reconectado a sw1.





NOTE: Nenhum link operacional entre switches (ISL) é necessário durante este procedimento. Isso ocorre porque as alterações na versão do RCF podem afetar a conectividade ISL temporariamente. Para garantir a operação ininterrupta do cluster, o procedimento a seguir migra todas as LIFs do cluster para o switch parceiro operacional enquanto executa as etapas no switch de destino.



=== Etapa 1: Prepare-se para a migração

. Se o AutoSupport estiver ativado neste cluster, suprima a criação automática de casos invocando uma mensagem do AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
onde _x_ é a duração da janela de manutenção em horas.

. Altere o nível de privilégio para avançado, digitando *y* quando solicitado a continuar:
+
`set -privilege advanced`

+
A mensagem avançada (*>) é exibida.

. Desativar a reversão automática nas LIFs do cluster:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`





=== Etapa 2: Configurar portas e cabos

. Determine o status administrativo ou operacional de cada interface de cluster.
+
Cada porta deve aparecer para cima. `Link` e `healthy` para `Health Status` .

+
.. Exibir os atributos da porta de rede:
+
`network port show -ipspace Cluster`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
.. Exibir informações sobre os LIFs e seus respectivos nós de origem:
+
`network interface show -vserver Cluster`

+
Cada LIF deve exibir `up/up` para `Status Admin/Oper` e `true` para `Is Home` .

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network interface show -vserver Cluster*

            Logical      Status     Network            Current     Current Is
Vserver     Interface    Admin/Oper Address/Mask       Node        Port    Home
----------- -----------  ---------- ------------------ ----------- ------- ----
Cluster
            node1_clus1  up/up      169.254.209.69/16  node1       e3a     true
            node1_clus2  up/up      169.254.49.125/16  node1       e3b     true
            node2_clus1  up/up      169.254.47.194/16  node2       e3a     true
            node2_clus2  up/up      169.254.19.183/16  node2       e3b     true

----
====


. As portas do cluster em cada nó são conectadas aos switches de cluster existentes da seguinte maneira (da perspectiva dos nós), utilizando o comando:
+
`network device-discovery show -protocol`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol cdp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /cdp
            e3a    c1 (6a:ad:4f:98:3b:3f)    0/1               -
            e3b    c2 (6a:ad:4f:98:4c:a4)    0/1               -
node2      /cdp
            e3a    c1 (6a:ad:4f:98:3b:3f)    0/2               -
            e3b    c2 (6a:ad:4f:98:4c:a4)    0/2               -
----
====
. As portas e switches do cluster estão conectados da seguinte forma (do ponto de vista dos switches) usando o comando:
+
`show cdp neighbors`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
c1# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute

Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 0/1           124     H          AFF-A400         e3a
node2                 0/2           124     H          AFF-A400         e3a
c2                    0/13          179     S I s      CN1610           0/13
c2                    0/14          175     S I s      CN1610           0/14
c2                    0/15          179     S I s      CN1610           0/15
c2                    0/16          175     S I s      CN1610           0/16

c2# *show cdp neighbors*

Capability Codes: R - Router, T - Trans-Bridge, B - Source-Route-Bridge
                  S - Switch, H - Host, I - IGMP, r - Repeater,
                  V - VoIP-Phone, D - Remotely-Managed-Device,
                  s - Supports-STP-Dispute


Device-ID             Local Intrfce Hldtme Capability  Platform         Port ID
node1                 0/1           124    H           AFF-A400         e3b
node2                 0/2           124    H           AFF-A400         e3b
c1                    0/13          175    S I s       CN1610           0/13
c1                    0/14          175    S I s       CN1610           0/14
c1                    0/15          175    S I s       CN1610           0/15
c1                    0/16          175    S I s       CN1610           0/16
----
====
. Verifique a conectividade das interfaces do cluster remoto:


[role="tabbed-block"]
====
.ONTAP 9.9.1 e posterior
--
Você pode usar o `network interface check cluster-connectivity` Comando para iniciar uma verificação de acessibilidade para conectividade do cluster e, em seguida, exibir os detalhes:

`network interface check cluster-connectivity start`e `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*NOTA:* Aguarde alguns segundos antes de executar o `show` comando para exibir os detalhes.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Todas as versões do ONTAP
--
Para todas as versões do ONTAP , você também pode usar o `cluster ping-cluster -node <name>` comando para verificar a conectividade:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1     e3a
Cluster node1_clus2 169.254.49.125 node1     e3b
Cluster node2_clus1 169.254.47.194 node2     e3a
Cluster node2_clus2 169.254.19.183 node2     e3b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
    Local 169.254.19.183 to Remote 169.254.209.69
    Local 169.254.19.183 to Remote 169.254.49.125
    Local 169.254.47.194 to Remote 169.254.209.69
    Local 169.254.47.194 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====
. [[passo 5]]No switch c2, desligue as portas conectadas às portas do cluster dos nós para realizar o failover dos LIFs do cluster.
+
[listing, subs="+quotes"]
----
(c2)# *configure*
(c2)(Config)# *interface 0/1-0/12*
(c2)(Interface 0/1-0/12)# *shutdown*
(c2)(Interface 0/1-0/12)# *exit*
(c2)(Config)# *exit*
(c2)#
----
. Mova as portas do cluster de nós do switch antigo c2 para o novo switch sw2, usando a cablagem apropriada compatível com o NVIDIA SN2100.
. Exibir os atributos da porta de rede:
+
`network port show -ipspace Cluster`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. As portas do cluster em cada nó agora estão conectadas aos switches do cluster da seguinte maneira, da perspectiva dos nós:
+
`network device-discovery show -protocol`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface         Platform
----------- ------ ------------------------- ----------------  ----------------
node1      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   0/1               -
            e3b    sw2 (b8:ce:f6:19:1a:7e)   swp3              -
node2      /lldp
            e3a    c1  (6a:ad:4f:98:3b:3f)   0/2               -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4              -
----
====
. No switch sw2, verifique se todas as portas do cluster de nós estão ativas:
+
`net show interface`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. No switch c1, desligue as portas conectadas às portas do cluster dos nós para realizar o failover das LIFs do cluster.
+
[listing, subs="+quotes"]
----
(c1)# *configure*
(c1)(Config)# *interface 0/1-0/12*
(c1)(Interface 0/1-0/12)# *shutdown*
(c1)(Interface 0/1-0/12)# *exit*
(c1)(Config)# *exit*
(c1)#
----
. Mova as portas do cluster de nós do switch antigo c1 para o novo switch sw1, usando a cablagem apropriada compatível com o NVIDIA SN2100.
. Verifique a configuração final do cluster:
+
`network port show -ipspace Cluster`

+
Cada porta deve exibir `up` para `Link` e `healthy` para `Health Status` .

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false

Node: node2
                                                                       Ignore
                                                 Speed(Mbps)  Health   Health
Port      IPspace    Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ---------- ---------------- ---- ----- ------------ -------- ------
e3a       Cluster    Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster    Cluster          up   9000  auto/100000  healthy  false
----
====
. As portas do cluster em cada nó agora estão conectadas aos switches do cluster da seguinte maneira, da perspectiva dos nós:
+
`network device-discovery show -protocol`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*

Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface       Platform
----------- ------ ------------------------- --------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3            -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4            -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4            -
----
====
. Nos switches sw1 e sw2, verifique se todas as portas do cluster de nós estão ativas:
+
`net show interface`

+
.Mostrar exemplo
[%collapsible]
====
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3a               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw2 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw2 (swp16)       Master: cluster_isl(UP)


cumulus@sw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- -----------------------
...
...
UP     swp3         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2    e3b               Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
====
. Verifique se ambos os nós possuem uma conexão com cada switch:
+
`net show lldp`

+
.Mostrar exemplo
[%collapsible]
====
O exemplo a seguir mostra os resultados apropriados para ambas as opções:

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3a
swp4       100G   Trunk/L2    node2               e3a
swp15      100G   BondMember  sw2                 swp15
swp16      100G   BondMember  sw2                 swp16

cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost          RemotePort
---------  -----  ----------  ------------------  -----------
swp3       100G   Trunk/L2    node1               e3b
swp4       100G   Trunk/L2    node2               e3b
swp15      100G   BondMember  sw1                 swp15
swp16      100G   BondMember  sw1                 swp16
----
====




=== Etapa 3: Verifique a configuração

. Ativar reversão automática nos LIFs do cluster:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. No switch sw2, desligue e reinicie todas as portas do cluster para acionar uma reversão automática de todas as LIFs do cluster que não estejam em suas portas de origem.


[role="tabbed-block"]
====
.Cumulus 4.4.3
--
[listing, subs="+quotes"]
----
cumulus@sw2:mgmt:~$ *net add interface swp1-14 link down*
cumulus@sw2:mgmt:~$ *net pending*
cumulus@sw2:mgmt:~$ *net commit*

(Wait for 5-10 seconds before re-enabling the ports)

cumulus@sw2:mgmt:~$ *net add interface swp1-14 link up*
cumulus@sw2:mgmt:~$ *net pending*
cumulus@sw2:mgmt:~$ *net commit*

(After executing the link state up command, the nodes detect the change and begin to auto-revert the cluster LIFs to their home ports)
----
--
.Cumulus 5.x
--
[listing, subs="+quotes"]
----
cumulus@sw2:mgmt:~$ *nv set interface swp1-14 link state down*
cumulus@sw2:mgmt:~$ *nv config apply*
cumulus@sw2:mgmt:~$ *nv show interface*

(Wait for 5-10 seconds before re-enabling the ports)

cumulus@sw2:mgmt:~$ *nv set interface swp1-14 link state up*
cumulus@sw2:mgmt:~$ *nv config apply*
cumulus@sw2:mgmt:~$ *nv show interface*

(After executing the link state up command, the nodes detect the change and begin to auto-revert the cluster LIFs to their home ports)
----
--
====
. [[passo 3]]Verifique se as LIFs do cluster retornaram às suas portas originais (isso pode levar um minuto):
+
`network interface show -vserver Cluster`

+
Se alguma das LIFs do cluster não tiver retornado à sua porta original, reverta-as manualmente. Você deve se conectar a cada console de gerenciamento de nó LIF ou SP/ BMC do nó local que possui o LIF:

+
`network interface revert -vserver Cluster -lif *`

. Altere o nível de privilégio de volta para administrador:
+
`set -privilege admin`

. Se você desativou a criação automática de casos, reative-a enviando uma mensagem do AutoSupport :
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.O que vem a seguir?
Depois de migrar seus switches, você pode link:../switch-cshm/config-overview.html["configurar monitoramento de integridade do switch"].
